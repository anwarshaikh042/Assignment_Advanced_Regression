{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a31ccf1",
   "metadata": {},
   "source": [
    "# House Price Predicition Regression Project\n",
    "\n",
    "A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia.\n",
    "\n",
    "The company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n",
    "\n",
    "The company wants to know:\n",
    "\n",
    "- Which variables are significant in predicting the price of a house, and\n",
    "- How well those variables describe the price of a house.\n",
    "\n",
    "## Business Goal\n",
    "\n",
    "You are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93cc81",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "\n",
    "1.   Importing modules, Reading the data\n",
    "2.   Analyzing Numerical Features\n",
    "    *   Checking Statistical summary\n",
    "    *   Checking Distribution of numerical features\n",
    "    *   Outlier Treatment\n",
    "    *   Inspecting Correlation\n",
    "    *   Missing Value Handling\n",
    "    *   Extracting new features and drop redundant ones\n",
    "    *   Correcting datatype\n",
    "    *   Univaritate and Bivariate Analysis, Data Visualization\n",
    "3.  Analyzing Categorical Features\n",
    "    *   Missing Value Handling\n",
    "    *   Encoding Categorical Features\n",
    "    *   Data Visualization\n",
    "    *   Dropping Redundant Features\n",
    "4.  Splitting data into Train and Test data\n",
    "    *   Transformation of Target Variable\n",
    "    *   Imputing Missing Values\n",
    "    *   Feature Scaling\n",
    "5.  Primary Feature Selection using RFE\n",
    "6.  Ridge Regression\n",
    "7.  Lasso Regression\n",
    "8.  Comparing model coefficients\n",
    "9.  Model Evaluation \n",
    "10. Choosing the final model and most significant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebf08e",
   "metadata": {},
   "source": [
    "   ### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for Model Buidling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm\n",
    "# for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# for supperssing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "house =  pd.read_csv('train.csv')\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff594515",
   "metadata": {},
   "source": [
    "Summary of the dataset : 1460 rows, 81 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical Analaysis\n",
    "house.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6687400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the numerical and categorical values\n",
    "numeric_house = house.select_dtypes(include=['int64','float64'])\n",
    "categorical_house = house.select_dtypes(include=[\"int64\",\"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4733aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "print(\"1 Numerical Data : \", numeric_house.columns)\n",
    "\n",
    "# Categorical\n",
    "print(\"2 Categorical Data :\", categorical_house.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94275444",
   "metadata": {},
   "source": [
    "### Analyzing Numerical Data\n",
    "\n",
    "**Outlier Detection**\n",
    "\n",
    "Checking the Percentage of Outliers for all the numerical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f46104",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_percentage={}\n",
    "\n",
    "for feature in numeric_house:\n",
    "    IQR=numeric_house[feature].quantile(.75)-numeric_house[feature].quantile(.25)\n",
    "    outliers_count=numeric_house[(numeric_house[feature]>(numeric_house[feature].quantile(.75)+1.5*IQR)) | (numeric_house[feature]<(numeric_house[feature].quantile(.25)-1.5*IQR))].shape[0]\n",
    "    outliers_percentage[feature]=round(outliers_count/numeric_house.shape[0]*100,2)\n",
    "    \n",
    "outliers_df = pd.DataFrame({\"Features\":list(outliers_percentage.keys()),\"Percentage\":list(outliers_percentage.values())})\n",
    "outliers_df.sort_values(by=\"Percentage\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb82c38",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "- Majority of numerical data have outliers\n",
    "- Dropping the all Outliers will causes loss information\n",
    "- hence ressigining fixed minimum values to these rows where feature value is outside the range of **[25th Percentilie - 1.5 IOR, 75th percentilie + 1.5 IQR]**\n",
    "- IQR or Iner Quartie Range = Difference between 75th percentilie and 25th percentilie values of features.\n",
    "- Target column 'SalePrice' is excluded in this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76645f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,percentage in outliers_percentage.items():\n",
    "    if feature!= 'SalePrice':\n",
    "        IQR = house[feature].quantile(.75) - house[feature].quantile(.25)\n",
    "        max_value = house[feature].quantile(.75)+1.5*IQR\n",
    "        min_value = house[feature].quantile(.25) - 1.5*IQR\n",
    "        house[feature][house[feature] > max_value] = max_value\n",
    "        house[feature][house[feature] < min_value] = min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset after reassigning minmum and maximum values\n",
    "house.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73716039",
   "metadata": {},
   "source": [
    "**Correlation in Numerical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e936375",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "sns.heatmap(numeric_house.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2d66d",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "- some of the features have high corelation with each others.\n",
    "- GarageCars and GarageArea (0.88)\n",
    "- GarageYrBlt and YearBlt (0.83)\n",
    "- TotalRmsAbvGrd and GrLivArea (0.83)\n",
    "- TotalBsmtSF and 1stflrSF (0.82)\n",
    "\n",
    "One feature from each of these pair will be dropped after visualization.\n",
    "\n",
    "**Univariate and Bivariate Analysis - Numerical Feature**\n",
    "\n",
    "**Analyzing Numerical Features with Continuous Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328995f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(12,12))\n",
    "for i, feature in enumerate(['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF']):\n",
    "    plt.subplot(9,3,i+1)\n",
    "    plt.subplots_adjust(hspace=2.0)\n",
    "    sns.scatterplot(x=house[feature], y=house['SalePrice'])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d74348",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- **LotFrontage**,**LotArea**,**TotalBsmtSF**,**1stFlrSF**,**2ndFlrSF** are showing the postive correlation with SalePrice.\n",
    "- **MSSubClass** his discrete values\n",
    "- **BsmtFinSF2** has single value and can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12761cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(12,12))\n",
    "for i, feature in enumerate (['LowQualFinSF','GrLivArea','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea']):\n",
    " plt.subplot(9,3,i+1)\n",
    " plt.subplots_adjust(hspace=2.0)\n",
    " sns.scatterplot(x=house[feature], y=house['SalePrice'])\n",
    " plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffa0fa",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- **'GrLivArea','GarageArea'**,showing postive correlation with SalePirce.\n",
    "- **'LowQualFinSF','EnclosedPorch,'3SsnPorch','ScreenPorch','PoolArea','Miscvar'** feature have single values and can be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def61999",
   "metadata": {},
   "source": [
    "**Visualizing the distribution of the numerical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(12,12))    \n",
    "for i, feature in enumerate(['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageCars','GarageArea','OpenPorchSF']):\n",
    "    plt.subplot(9,3,i+1)\n",
    "    plt.subplots_adjust(hspace=2.0)\n",
    "    sns.distplot(house[feature])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aae3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "house[['LowQualFinSF','GrLivArea','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b9363",
   "metadata": {},
   "source": [
    "Removing these features having fixed values as they won't contribute in predicting SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "house[['LowQualFinSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.drop(['LowQualFinSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal'], axis=1, inplace=True)\n",
    "\n",
    "# checking the remaing Columns\n",
    "house.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb689614",
   "metadata": {},
   "source": [
    "**Analyzing the Numerical Values with Discrete Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0722c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "house[['OverallQual','OverallCond','MoSold','YrSold','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','YearBuilt','YearRemodAdd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(12,12))    \n",
    "for i, feature in enumerate(['OverallQual','OverallCond','MoSold','YrSold','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','YearBuilt','YearRemodAdd']):\n",
    "    plt.subplot(9,3,i+1)\n",
    "    plt.subplots_adjust(hspace=2.0)\n",
    "    sns.barplot(x=house[feature], y=house['SalePrice'])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7cea3",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "- 'OverallQual': More the rating of the features more the SalePrice (target Variable)\n",
    "- 'OverallCond' : SalePrice is highest for rating 5.\n",
    "- 'MoSold' and 'YrSold' : SalePrice  does not show strong trend depending on month and year which realty is sold.\n",
    "- 'FullBath' : 3rd and \"HalfBath\": 1 is highest SalePrice.\n",
    "- 'TotRmsAbvGrd': More the number of total rooms grade more the SalePrice.\n",
    "- 'GarageYrBlt','YearBuilt','YearRemodAdd','YrSold': Will extract new features from to identify any trend.\n",
    "- 'BstmFullBath','KitchenAbvGr': Need Further inspection for meaningful insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "house[['BsmtFullBath','KitchenAbvGr','GarageYrBlt','YearBuilt','YearRemodAdd']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b290f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(house['BsmtFullBath'].value_counts())\n",
    "print(house['KitchenAbvGr'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ec803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the KitchenAbvGr for not having useful information\n",
    "house.drop(['KitchenAbvGr'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244099c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "house[['GarageYrBlt','YearBuilt','YearRemodAdd','YrSold']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the year related features into numbers of years.\n",
    "for feature in ['GarageYrBlt','YearBuilt','YearRemodAdd','YrSold']:\n",
    "    house[feature] = 2021 - house[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.subplots(figsize=(12,12))\n",
    "\n",
    "for i, feature in enumerate(['GarageYrBlt','YearBuilt','YearRemodAdd','YrSold']):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    plt.subplots_adjust(hspace=2.0)\n",
    "    sns.scatterplot(x=house[feature], y=house['SalePrice'])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9066a",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "- For Most the realty properties Garage is built within 20 years. SalePrice is more recently built Garages.\n",
    "- SalePrice is more than lower value of YearBuilt i.e. more recently build houses.\n",
    "- Recently remodelled houses (lower values of YearRomdAdd) have higher SalePrice.\n",
    "- YrSold still does not any sigmificant trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b773f0",
   "metadata": {},
   "source": [
    "**Missing Value Handling - Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16975945",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature: Percentage of Missing Value\")\n",
    "print(\"====================================\")\n",
    "for feat in house.select_dtypes(exclude=['object']).columns:\n",
    "    if house[feat].isnull().any():\n",
    "        print(feat,\" : \", round(house[feat].isnull().sum()/house.shape[0],2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since MasVnrArea has only 1% data missing, droping the row with Null Values in MasVnrArea  \n",
    "# Dropping the ID columns as it doesnot contribute towards predicting SalePrice.\n",
    "\n",
    "house = house[~house['MasVnrArea'].isnull()]\n",
    "house.drop(['Id'],axis=1, inplace=True)\n",
    "numeric_house.drop(['Id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of remaining columns\n",
    "house.columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99806fbb",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "- GarageCars and GarageArea (Correlation Coefficient = 0.88) dropping GarageCars\n",
    "- GarageYrBlt and YearBlt (Correlation Coefficient = 0.83) dropping GarageYrBlt for high correlation and containing missing value.\n",
    "- TotalRmsAbvGrd and GrLivArea (Correlation Coefficient = 0.83) dropping GrLivArea\n",
    "- TotalBsmtSF and 1stflrSF (Correlation Coefficient = 0.82) dropping TotalBsmtSF\n",
    "- Missing Value Imputation to be done for house[\"LotFrontage\"] after spilitting data into train and test set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463af352",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.drop(['GarageCars','GarageYrBlt','GrLivArea','TotalBsmtSF'], axis=1, inplace=True)\n",
    "\n",
    "# Checking the number of remaining columns\n",
    "print(house.columns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a16ee",
   "metadata": {},
   "source": [
    "### Analyzing Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Feature in the DataFrames\n",
    "\n",
    "categorical_house.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315267e6",
   "metadata": {},
   "source": [
    "**Missing Value Handling - Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature: Percentage of Missing Value\")\n",
    "print(\"====================================\")\n",
    "for feat in house.select_dtypes(include=['object']).columns:\n",
    "    if house[feat].isnull().any():\n",
    "        print(feat, ':' , round(house[feat].isnull().sum()/house[feat].shape[0],2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "house['Electrical'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house['PoolQC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96081caf",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- For 'Alley' Nan Means 'No access to alley.\n",
    "- For 'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2' Nan_means \"No Bassement\"\n",
    "- For GarageType, GarageFinish, GarageQual, GarageCond Nan means \"No Garage\"\n",
    "- Fpr FriplaceQu and Fence Nan means 'No Fire' Place and 'No Fence'\n",
    "- MiscFeature - Nan means no additional features mentioned.\n",
    "\n",
    "All these feature will be imputed with meaningful values in place of missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e237bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_categorical_feat = ['Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','GarageCond','FireplaceQu','Fence','MiscFeature']\n",
    "print(house[mv_categorical_feat].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Missing Values with \"Not_applicable\"\n",
    "house[mv_categorical_feat]= house[mv_categorical_feat].fillna(value=\"Not_applicable\",axis=1)\n",
    "\n",
    "# Check after imputation\n",
    "print(house[mv_categorical_feat].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e50c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"PoolQC\" for very high percentage of data imbalance\n",
    "house.drop(['PoolQC'], axis=1, inplace=True)\n",
    "\n",
    "# dropping rows with null values in Electrical for very low missing value count.\n",
    "house.dropna(subset=[\"Electrical\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature : Percentage of Missing Values\")\n",
    "print(\"======================================\")\n",
    "for feat in house.columns:\n",
    "    print(feat, ':', round(house[feat].isnull().sum()/house[feat].shape[0], 2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6ff8d",
   "metadata": {},
   "source": [
    "Missing Values imputation will be done after Spliting Training and testing set avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the boxplot for SalePrice against different features given the list of features\n",
    "\n",
    "def generate_boxplot(feature_list):\n",
    "    fig=plt.subplots(figsize=(20,16))\n",
    "    for i, feature in enumerate(feature_list):\n",
    "        plt.subplot(4, 2, i+1)\n",
    "        plt.subplots_adjust(hspace=2.0)\n",
    "        sns.boxplot(x=house[feature], y=house['SalePrice'])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988e083",
   "metadata": {},
   "source": [
    "divided the ordinal feature into smaller segement and Visualizing their impact on SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fd560",
   "metadata": {},
   "source": [
    "**Analyzing Orderred Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0225060",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_features = ['LotShape', 'Utilities', 'LandSlope', 'HouseStyle', 'ExterQual', 'ExterCond']\n",
    "generate_boxplot(ext_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357809b",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "- LotShape : Slightly irregular LotShape have the highest SalePrice\n",
    "- Utilities : Most of the house in the dataset have all the public utilities\n",
    "- LandSlope : House at severse land slope have lowest SalePrice\n",
    "- HouseStyle : 2 storied houses have the highest SalePrice\n",
    "- ExterQual : House with Excellent qualtity of material on the exterior have the highest SalePrice\n",
    "- ExterCond : House with Excellent condition of material on the exterior have the highest SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc677a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_features = ['HeatingQC','KitchenQual','Functional','FireplaceQu']\n",
    "generate_boxplot(int_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06579ee",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "- House having excellent heating quality and Kitchen quality have highest SalePrice\n",
    "- House With Typical funcationally have highest SalePrice. There are very few house that are severely damaged\n",
    "- SalePirce range in Largest for house with average firplace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab72761",
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_feature = ['GarageFinish','GarageQual','GarageCond']\n",
    "generate_boxplot(garage_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1194b",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "- SalePrice is highest of Garage is Finished\n",
    "- The Range of SalePrice is widest for Typical/Average Garage qualtiy and Condition.\n",
    "- there are very few house with excellent condition of garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d143b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bassement_feature = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\n",
    "generate_boxplot(bassement_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dfab04",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "- House with Excellwnt Quality bassement have highest SalePrice\n",
    "- House with good living quarters (BsmtFinshType1=GLQ) have highest SalePrice\n",
    "- A lost of house have unfinished basement or no bassement (label = Not_applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e415556",
   "metadata": {},
   "source": [
    "**Ecoding Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotShape into numerical values\n",
    "house['LotShape']=house['LotShape'].map({'IR1':0,'IR2':1,'IR3':2,'Reg':3})\n",
    "# Utilities into numerical values\n",
    "house['Utilities']=house['Utilities'].map({'AllPub':3,'NoSewr':2,'NoSeWa':1,'ELO':0})\n",
    "# LotShape into numerical values\n",
    "house['LandSlope']=house['LandSlope'].map({'Gtl':0,'Mod':1,'Sev':2})\n",
    "# HouseStyle into numerical values\n",
    "house['HouseStyle']=house['HouseStyle'].map({'1Story':0,'1.5Fin':1,'1.5Unf':2,'2Story':3,'2.5Fin':4,'2.5Unf':5,'SFoyer':6,'SLvl':7})\n",
    "# ExterQual into numerical values\n",
    "house['ExterQual']=house['ExterQual'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "# ExterCond into numerical values\n",
    "house['ExterCond']=house['ExterCond'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "# BsmtQual into numerical values\n",
    "house['BsmtQual']=house['BsmtQual'].map({'Not_applicable':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "# BsmtCond into numerical values\n",
    "house['BsmtCond']=house['BsmtCond'].map({'Not_applicable':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "# BsmtExposure into numerical values\n",
    "house['BsmtExposure']=house['BsmtExposure'].map({'Not_applicable':0,'No':1,'Mn':2,'Av':3,'Gd':4})                                                                              \n",
    "# BsmtFinType1 into numerical values\n",
    "house['BsmtFinType1']=house['BsmtFinType1'].map({'Not_applicable':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\n",
    "# BsmtFinType2 into numerical values\n",
    "house['BsmtFinType2']=house['BsmtFinType2'].map({'Not_applicable':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\n",
    "# HeatingQC into numerical values\n",
    "house['HeatingQC']=house['HeatingQC'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "# CentralAir into numerical values\n",
    "house['CentralAir']=house['CentralAir'].map({'N':0,'Y':1})\n",
    "# KitchenQual into numerical values\n",
    "house['KitchenQual']=house['KitchenQual'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "# GarageFinish into numerical values\n",
    "house['GarageFinish']=house['GarageFinish'].map({'Not_applicable':0,'Unf':1,'RFn':2,'Fin':3})\n",
    "# GarageQual into numerical values\n",
    "house['GarageQual']=house['GarageQual'].map({'Not_applicable':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "# GarageCond into numerical values\n",
    "house['GarageCond']=house['GarageCond'].map({'Not_applicable':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "# Functional into numerical values\n",
    "house['Functional']=house['Functional'].map({'Typ':0,'Min1':1,'Min2':3,'Mod':4,'Maj1':5,'Maj2':6,'Fa':7,'Sev':8,'Sal':9})\n",
    "# FireplaceQu into numerical values\n",
    "house['FireplaceQu']=house['FireplaceQu'].map({'Not_applicable':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ececd39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checkingthe Features after encoding\n",
    "house[['LotShape', 'Utilities', 'LandSlope', 'HouseStyle', 'ExterQual', 'ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "'HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_feature = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2','BldgType','RoofStyle',\n",
    "'RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating','Electrical','GarageType','PavedDrive','Fence',\n",
    "'MiscFeature','SaleType','SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot(['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de78f2e",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "- Most of the houses do not have alley\n",
    "- Neighborhood has a lots of labels, using one hot coding directly would leads to high numbers of additional columns\n",
    "- house claasified as MSZoning = RL or Residentil Low density have the highest SalePrice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d02d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot(['Condition1','Condition2','BldgType','RoofStyle',\n",
    "'RoofMatl','Exterior1st','Exterior2nd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8c6e5",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "- Normal Condition ( condition1 = Norm and Condtion2 =Nrm) House are likely to have high SalePrice\n",
    "- Feature like 'RoofMat Exterior1st,Exterior2nd have labels with very few data this cannot contiribute in prediciting SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8752d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_boxplot(['MasVnrType','Foundation','Heating','Electrical','GarageType','PavedDrive','Fence',\n",
    "'MiscFeature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c81be",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "- Houses with foundation of poured concrete ( FOundation =PConc) and/or Electical with Standard Circul Break and/or Heating Type = GasA have the highest price\n",
    "- Houses With Attached and built in garage have high SalePrice\n",
    "- Most of the House do not have fence(fence=Not fence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot(['SaleType','SaleCondition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b8b3f",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "- Most of the house are newly built houses with warranty deed have high SalePrice\n",
    "- Sale Condition = Normal leads to high SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bddfa1",
   "metadata": {},
   "source": [
    "**Encoding Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db134fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(house[unordered_feature],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d540ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42004f1b",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "- Adding 144 features to exisiting dataset will make the model complex\n",
    "- From the above boxplot for some categorical features only labels is dominating over others.\n",
    "- in dummy_df any label have same values like95% or more will be  dropped as those new features are highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8176700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_to_drop = []\n",
    "for feat in dummy_df.columns:\n",
    "    if dummy_df[feat].value_counts()[0]/dummy_df.shape[0]>=0.95:\n",
    "        dummies_to_drop.append(feat)\n",
    "print(dummies_to_drop)\n",
    "print(len(dummies_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef19b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the highly imbalanced dummy varaiables\n",
    "dummy_df = dummy_df.drop(dummies_to_drop, axis=1)\n",
    "\n",
    "print(dummy_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b41e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the dummy variables to the original dataframe\n",
    "house = pd.concat([house,dummy_df],axis=1)\n",
    "\n",
    "# Dropping the redundant columns\n",
    "house = house.drop(unordered_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f264b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "house.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6561f",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house.drop(['SalePrice'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Distribution of Sale')\n",
    "sns.distplot(house[\"SalePrice\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07beee4b",
   "metadata": {},
   "source": [
    "**Comment:** Since SalePrice is highly Skewed, Checking the Distribution of transformed SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fba642",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(house['SalePrice']))\n",
    "plt.title('Distribution of log transformed SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformed SalePrice is normaliy distributed, hence te transformed data will be used for model building\n",
    "\n",
    "y = np.log(house['SalePrice'])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da718b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['LotFrontage'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34745369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing value of LotFrontage after spliting training and testing the dataset to prevent data leakage\n",
    "\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "si.fit(X_train[['LotFrontage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e62530",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['LotFrontage']] = si.transform(X_train[['LotFrontage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b17644",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['LotFrontage']] = si.transform(X_test[['LotFrontage']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adfc63",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4655fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d975fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_scaled = pd.DataFrame(data=ss.transform(X_train), columns=X_train.columns)\n",
    "X_te_scaled = pd.DataFrame(data=ss.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the features after \n",
    "\n",
    "print(X_tr_scaled)\n",
    "print(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511daaa",
   "metadata": {},
   "source": [
    "### Initial Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf409360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the number of features = n, the function prints and returns top n features selected by RFE\n",
    "def top_n_features(n, X_tr_scaled, y_train):\n",
    "    top_n_cols = []\n",
    "\n",
    "    linear_m = LinearRegression()\n",
    "    linear_m.fit(X_tr_scaled, y_train)\n",
    "    rfe = RFE(linear_m)  # Remove 'n' from here\n",
    "\n",
    "    rfe = rfe.fit(X_tr_scaled, y_train)\n",
    "    rfe.support_[:n] = True\n",
    "\n",
    "    print(\"Top %d features: \" % n)\n",
    "    rfe_ranking = list(zip(X_tr_scaled.columns, rfe.support_, rfe.ranking_))\n",
    "\n",
    "    for i in rfe_ranking:\n",
    "        if i[1]:\n",
    "            top_n_cols.append(i[0])\n",
    "    print(top_n_cols)\n",
    "    return top_n_cols\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking top 45, 50, and 55 features\n",
    "top_45 = top_n_features(45, X_tr_scaled, y_train)\n",
    "top_50 = top_n_features(50, X_tr_scaled, y_train)\n",
    "top_55 = top_n_features(55, X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89328c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the Training Data and list of features, this will provides the statisitical summary of the model\n",
    "# This Will be  used to check adjusted R_squared value for top 45, 50, and 55 Features\n",
    "\n",
    "def build_regressor(X_train, y_train, cols):\n",
    "    X_train_ols = sm.add_constant(X_train[cols])\n",
    "    lin_reg = sm.OLS(y_train.values.reshape(-1, 1), X_train_ols).fit()\n",
    "    print(lin_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_regressor(X_tr_scaled,y_train,top_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6adfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_regressor(X_tr_scaled,y_train,top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_regressor(X_tr_scaled,y_train,top_55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03da70",
   "metadata": {},
   "source": [
    "**Comments:** By inspecting the Ajusted R-square value of linear Regression model with top_45,top_50,and top_55 features seem to be optimum as model with 50 and 55 features have same the adjusted R-square value on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_tr_scaled[top_50]\n",
    "X_test_rfe = X_te_scaled[top_50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66423794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_train, X_test, y_train, params, model='ridge'):\n",
    "    if model == 'ridge':\n",
    "        estimator_model = Ridge()\n",
    "    else:\n",
    "        estimator_model = Lasso()\n",
    "    model_cv = GridSearchCV(estimator=estimator_model,\n",
    "                           param_grid=params,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           cv=5,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    alpha = model_cv.best_params_['alpha']\n",
    "    print(\"Optimum alpha for %s is %f\" % (model, alpha))\n",
    "    final_model = model_cv.best_estimator_\n",
    "    \n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_train_pred = final_model.predict(X_train)\n",
    "    y_test_pred = final_model.predict(X_test)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    print(model, \"Regression with alpha\", alpha)\n",
    "    print(\"===========================\")\n",
    "    print('R2 score (train):', r2_score(y_train, y_train_pred))\n",
    "    print('R2 score (test):', r2_score(y_test, y_test_pred))\n",
    "    print('RMSE (train):', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "    print('RMSE (test):', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "    \n",
    "    return final_model, y_test_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a24a7",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdfb0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of alphas to tune\n",
    "params = {'alpha': [0.0001,0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10, 20, 50, 100, 500, 1000]}\n",
    "ridge_final_model, y_test_predicted = build_model(X_train_rfe, X_test_rfe, y_train, params, model='ridge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0577f",
   "metadata": {},
   "source": [
    "**Comments:** Ridge Regression model was able to achieve R2 Score is 87% test data of variance in test data can be explained by model Root mean square error = 0.1531 on test data that means the prediction made by the model can of by 0.1531 units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7520a0a",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={'alpha':[0.000001,0.00001,0.0001,0.001,0.01,0.1,1.0,10,100,500,10000]}\n",
    "\n",
    "lasso_final_model, y_test_predicted = build_model(X_train_rfe, X_test_rfe, y_train, params, model='lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7bd37",
   "metadata": {},
   "source": [
    "### Comparing Model COefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a4f92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_coefficients = pd.DataFrame(index=X_test_rfe.columns)\n",
    "model_coefficients.rows = X_test_rfe.columns\n",
    "\n",
    "model_coefficients['Ridge (alpha=9.0)']=ridge_final_model.coef_\n",
    "model_coefficients['Lasso (alpha=0.0001)'] = lasso_final_model.coef_\n",
    "pd.set_option('display.max_row',None)\n",
    "model_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db825ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the prediction to its orginal scale (anti log)\n",
    "\n",
    "test_prediction = np.around(np.exp(y_test_predicted)).astype(int)\n",
    "print(test_prediction[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6d8b8",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf84b28",
   "metadata": {},
   "source": [
    "Lasso Regression product slightly R2 score on test data than Ridge Regression. Choosing Lasso as the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 feature ordered by feature importance in lasso Regression\n",
    "model_coefficients[['Lasso (alpha=0.0001)']].sort_values(by='Lasso (alpha=0.0001)',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11549a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients[['Lasso (alpha=0.0001)']].sort_values(by='Lasso (alpha=0.0001)',ascending=False).index[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45df2b",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b741b24",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- First the housing data is read and analyzed dividing the features into numerical and categorical types.\n",
    "\n",
    "\n",
    "- SalePrice is the target column here.\n",
    "\n",
    "\n",
    "- All the features are then analyzed, missing data handling, outlier detection, data cleaning are done. Trend of SalePrice is \n",
    "observed for change in individual features.\n",
    "\n",
    "\n",
    "- New features are extracted, redundant features dropped and categorical features are encoded accordingly.\n",
    "\n",
    "\n",
    "- Then the data in split into train and test data and feature scaling is performed.\n",
    "\n",
    "\n",
    "- Target variable SalePrice is right skewed. Natural log of the same is Normal distributed, hence for model building, natural log of SalePrice is considered.\n",
    "\n",
    "\n",
    "- Creating dummy variables increased the number of features greatly, highly imbalanced columns are dropped.\n",
    "\n",
    "\n",
    "- Top 50 features are selected through RFE and adjusted R-square. 50 features : \n",
    "['MSSubClass', 'LotArea', 'LandSlope', 'OverallQual', 'OverallCond', 'YearBuilt', 'BsmtQual', 'BsmtExposure', 'BsmtFinSF1', 'BsmtUnfSF', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'BsmtFullBath', 'HalfBath', 'KitchenQual', 'Functional', 'Fireplaces', 'GarageFinish', 'GarageArea', 'GarageQual', 'OpenPorchSF', 'MSZoning_RL', 'Street_Pave', 'LotConfig_CulDSac', 'Neighborhood_Edwards', 'Neighborhood_NAmes', 'Neighborhood_NWAmes', 'Neighborhood_NridgHt', 'Neighborhood_Somerst', 'Condition1_Feedr', 'Condition1_Norm', 'Condition2_Norm', 'BldgType_TwnhsE', 'RoofStyle_Gable', 'RoofStyle_Hip', 'Exterior1st_HdBoard', 'Exterior1st_Wd Sdng', 'Exterior2nd_HdBoard', 'Exterior2nd_Wd Sdng', 'MasVnrType_BrkFace', 'MasVnrType_None', 'MasVnrType_Stone', 'Foundation_PConc', 'Heating_GasA', 'GarageType_Not_applicable', 'PavedDrive_Y', 'SaleCondition_Normal', 'SaleCondition_Partial']\n",
    "\n",
    "\n",
    "- Ridge and Lasso Regression Model are built with optimum alpha calculated in GridSearchCV method.\n",
    "Optimum alpha = 9.0 for ridge and 0.0001 for lasso model.\n",
    "\n",
    "\n",
    "- Model evaluation is done with R2 score and Root Mean Square Error.\n",
    "\n",
    "\n",
    "- Lasso Regression is chosen as final model for having slightly better R-square value on test data.\n",
    "\n",
    "\n",
    "- Out of 50 features in the final model, top 10 features in order of descending importance are ['1stFlrSF', '2ndFlrSF', 'OverallQual', 'OverallCond', 'SaleCondition_Partial', 'LotArea', 'BsmtFinSF1','SaleCondition_Normal', 'MSZoning_RL', 'Neighborhood_Somerst']\n",
    "\n",
    "\n",
    "- Model coefficients are listed in a table along with the corresponding features , for example natural log of SalePrice will change by 0.124911 with unit change in the feature '1stFlrSF' when all the features remain constant. Negative sign in the coefficient signifies negative correlation between the predictor and target variable. \n",
    "\n",
    "\n",
    "- Predicted value of SalePrice is tranformed into its original scale by performing antilog. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a1f1a",
   "metadata": {},
   "source": [
    "### FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57330eb7",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "What is the optimal value of alpha for ridge and lasso regression? What will be the changes in the model if you choose double the value of alpha for both ridge and lasso? What will be the most important predictor variables after the change is implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5fc1f",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "The Optimual values of alpha of ridge and lasso is 8.000000 and 0.001000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea380e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Double the alpha values\n",
    "doubled_alpha_ridge = model_coefficients['Ridge (alpha=8.0)'] * 2\n",
    "doubled_alpha_lasso = model_coefficients['Lasso (alpha=0.0001)'] * 2\n",
    "\n",
    "# Create DataFrames to store coefficients\n",
    "ridge_coeffs = pd.DataFrame(index=model_coefficients.index)\n",
    "lasso_coeffs = pd.DataFrame(index=model_coefficients.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59c06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doubled_alpha_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca307ca",
   "metadata": {},
   "source": [
    "**Ridge Regression:**\n",
    "\n",
    "- If you double the alpha value in Ridge regression, it will increase the regularization strength. This means that the model will be penalized more for having large coefficient values. As a result, the coefficients of the predictors will tend to become smaller.\n",
    "- This increased regularization will lead to a simpler model that is less likely to overfit the training data. It can help prevent multicollinearity by encouraging coefficients to be small but non-zero.\n",
    "- After doubling alpha, the most important predictor variables will likely remain the same as they were before the change. However, their coefficient values will decrease in magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f723b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubled_alpha_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92341d",
   "metadata": {},
   "source": [
    "**Lasso Regression:**\n",
    "\n",
    "- Doubling the alpha value in Lasso regression will also increase the regularization strength. Lasso uses L1 regularization, which encourages some coefficients to be exactly zero. Increasing alpha makes it more likely that Lasso will set more coefficients to zero.\n",
    "- The impact on the model will be sparsity in the coefficient vector. Many predictor variables may become irrelevant (have coefficients set to zero), effectively performing feature selection. Only a subset of the most important predictor variables will have non-zero coefficients.\n",
    "- After doubling alpha, the most important predictor variables will be those that Lasso retains with non-zero coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7c55f",
   "metadata": {},
   "source": [
    "**Question 2:**\n",
    "\n",
    "You have determined the optimal value of lambda for ridge and lasso regression during the assignment. Now, which one will you choose to apply and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1805e",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "**Ridge Regression:**\n",
    "\n",
    "- Ridge adds L2 regularization to the linear regression, which penalizes the sum of squared coefficients.\n",
    "- It is effective when you believe that most of the features are relevant, but I want to prevent multicollinearity and control the magnitude of the coefficients.\n",
    "- Ridge can be a good choice when we have a large number of features, and we want to avoid feature selection.\n",
    "\n",
    "**Lasso Regression:**\n",
    "\n",
    "- Lasso adds L1 regularization, which can lead to sparse coefficient vectors by setting some coefficients to exactly zero.\n",
    "- It is useful when we suspect that many features are irrelevant, and we want automatic feature selection.\n",
    "- Lasso can be a good choice when we have a high-dimensional dataset and want to simplify the model by eliminating unimportant predictors.\n",
    "- In this Problem Statement, since Lasso has a slightly higher R2 score on the test data, it indicates that Lasso's feature selection capability might be more suitable for your dataset, effectively reducing the impact of irrelevant predictors. The choice of Lasso as the final model aligns with goal of achieving better predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13db9c",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a84498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients[['Lasso (alpha=0.0001)']].sort_values(by='Lasso (alpha=0.0001)',ascending=False).index[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67bb87",
   "metadata": {},
   "source": [
    "Refrence link click here - git@github.com:anwarshaikh042/Assignment_Advanced_Regression.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
